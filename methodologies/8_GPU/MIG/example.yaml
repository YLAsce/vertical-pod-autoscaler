apiVersion: v1
kind: Pod
metadata:
  name: test-1
spec:
  restartPolicy: OnFailure
  containers:
  - name: gpu-test
    image: nvcr.io/nvidia/pytorch:23.07-py3
    command: ["python", "-c"]
    args:
      - |
        import torch
        import time
        a = torch.randn(100, 100).cuda()
        b = torch.randn(100, 100).cuda()
        while True:
          c = torch.matmul(a, b)
          time.sleep(30)
    resources:
      limits:
          nvidia.com/gpu: 1
  nodeSelector:
      nvidia.com/gpu.product : NVIDIA-H100-PCIe-MIG-1g.10gb
---
apiVersion: v1
kind: Pod
metadata:
  name: test-2
spec:
  restartPolicy: OnFailure
  containers:
  - name: gpu-test
    image: nvcr.io/nvidia/pytorch:23.07-py3
    command: ["python", "-c"]
    args:
      - |
        import torch
        import time
        a = torch.randn(100, 100).cuda()
        b = torch.randn(100, 100).cuda()
        while True:
          c = torch.matmul(a, b)
          time.sleep(30)
    resources:
      limits:
          nvidia.com/gpu: 1
  nodeSelector:
      nvidia.com/gpu.product : NVIDIA-H100-PCIe-MIG-1g.10gb